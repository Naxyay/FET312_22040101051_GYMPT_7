{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5697c3ad-0eb1-4560-b49f-0f7015c30ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers pillow requests bitsandbytes accelerate -q\n",
    "!pip install --upgrade torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723e6907-35fd-4aba-bdb6-497fec00d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d175cbd-b1ba-49fa-a4d6-52e0abcf4342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çalışma Ortamı: CUDA\n",
      "GPU Modeli: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "VRAM: 6.44 GB\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Çalışma Ortamı: {device.upper()}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU Modeli: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"UYARI: CPU kullanıyorsunuz. Model çok yavaş çalışacaktır!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4a1b11-0ef7-4a9e-9147-db7555f8c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041fd60c61ee4701befc7365b04e4f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla yüklendi!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\"\n",
    ")\n",
    "\n",
    "print(\"Model başarıyla yüklendi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4bdf73-05e3-43cc-aefe-1f199b34410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Sen yardımcı bir aşçısın. \n",
    "Sadece öğle yemeği için, toplamı yaklaşık 500 kalori olan sağlıklı\n",
    "ve tek bir tabak yemek tarifi veya menüsü öner.\n",
    "\"\"\"\n",
    "\n",
    "text_prompt = processor.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": question}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt],\n",
    "    images=None,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ").to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76347178-7fcd-4c3b-a62a-ff15426559ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== MODEL CEVABI ======\n",
      "\n",
      "Tabii ki, genellikle öğle yemeğinizde 2-3 adet küçük ve kesinlikle protein içeren beslenme maddesi tüketirsiniz. Bu nedenle, bu tür bir yemek tarifini oluşturmak için birkaç seçenek öneririm:\n",
      "\n",
      "1. Tavuklu Kuru Yumurta: Tavuklu kuru yumurta, protein kaynağıdır ve aynı zamanda kalorileri azaltır. Ayrıca, bu ürün, daha fazla yağ içermez.\n",
      "\n",
      "2. Çay ve Zeytinyağı: Çay ve zeytinyağı, enerji sağlar ve kalorileri azaltır. Ayrıca, bu ürünler, beslenme sırasında enerji kaybını önler.\n",
      "\n",
      "3. Soslu Tavuk: Tavuklu soslu yemekleri, protein ve kalorileri artırır. Ayrıca, sosunun etkisiyle beslenme sürecinde enerji kaybını önler.\n",
      "\n",
      "4. Tavuklu Kuru Biberli Yumurta: Tavuklu kuru biberli yumurta, protein ve kalorileri artırır. Ayrıca, bu ürün,\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "answer = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "\n",
    "response = answer.split(\"assistant\")[-1].strip()\n",
    "\n",
    "print(\"\\n====== MODEL CEVABI ======\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d40f0c6-24e2-449d-9268-3013e6a1fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Untitled.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3ba3a-7495-46f4-a994-ed1d87167ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qwen)",
   "language": "python",
   "name": "qwen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
