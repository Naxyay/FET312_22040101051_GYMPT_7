{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526c4d02-34ea-4235-9022-4d856f37fc19",
   "metadata": {},
   "source": [
    "# Environment Kurulumunda Kullanılanlar\n",
    "1)  conda create -n qwen python=3.10 -y\n",
    "2)  conda activate qwen\n",
    "3)  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "4)  pip install transformers pillow requests bitsandbytes accelerate ipywidgets tqdm\n",
    "5)  jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b3de5-51be-42a3-b54a-e1255ec856fc",
   "metadata": {},
   "source": [
    "## Import Kısmı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87f3c97-d152-4966-abf0-4ba6b509c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfc33b-1731-4f19-a490-b4ec8625dff4",
   "metadata": {},
   "source": [
    "## Çalışma Ortamının Görüntülenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d175cbd-b1ba-49fa-a4d6-52e0abcf4342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çalışma Ortamı: CUDA\n",
      "GPU Modeli: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "VRAM: 6.44 GB\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Çalışma Ortamı: {device.upper()}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU Modeli: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"UYARI: CPU kullanıyorsunuz. Model çok yavaş çalışacaktır!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d290f-2a66-404f-98a3-32d81f2abc0f",
   "metadata": {},
   "source": [
    "## Model Kurulumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4a1b11-0ef7-4a9e-9147-db7555f8c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041fd60c61ee4701befc7365b04e4f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla yüklendi!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\"\n",
    ")\n",
    "\n",
    "print(\"Model başarıyla yüklendi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa126ad-7645-41ed-a21f-c4099643591d",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae4bdf73-05e3-43cc-aefe-1f199b34410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Bana kahvaltı için 800 kalorilik bir menü önerir misin? Yumurta yemiyorum ona göre ayarla lütfen.\"\n",
    "\n",
    "text_prompt = processor.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": question}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt],\n",
    "    images=None,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ").to(model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349caa78-96ac-45e2-a3a3-5dbfb37e9880",
   "metadata": {},
   "source": [
    "## Cevap Üretimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76347178-7fcd-4c3b-a62a-ff15426559ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== MODEL CEVABI ======\n",
      "\n",
      "Tabii ki, benimle ilgili bir öneri yapmak isterseniz, size en iyi seçenekler hakkında bilgi vermek için daha fazla detay sağlayabilirsiniz. İşte bir öneri:\n",
      "\n",
      "1. Kuru Balık: 250 gr\n",
      "2. Tavuk: 150 gr\n",
      "3. Patates: 100 gr\n",
      "4. Zeytinyağı: 100 ml\n",
      "5. Çay: 1 tuzu\n",
      "\n",
      "Bu menüdeki kalori sayısı 800 kaloriye ulaşır. Bu menü, sağlıklı ve gecikme riskini azaltan bir mutfak planıdır. Ayrıca, bu menüde bulunan balık ve patates, besinlerinizi artırarak enerji ihtiyacını karşılamaktadır.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "answer = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "\n",
    "response = answer.split(\"assistant\")[-1].strip()\n",
    "\n",
    "print(\"\\n====== MODEL CEVABI ======\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56feb1-6179-47e4-a355-559af693d060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qwen)",
   "language": "python",
   "name": "qwen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
